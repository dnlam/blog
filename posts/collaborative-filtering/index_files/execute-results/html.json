{
  "hash": "cfbd2f1718468fc705c4b0ac7e183bfc",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Recommendation System with Collaborative Filtering\"\n# author: \"Lam Dinh\"\ndate: \"2022-04-20\"\ncategories: [Recommendation, Collaborative Filtering, Code]\nimage: \"collab_filtering.png\"\npdf-engine: pdflatex\nformat:\n  html:\n    code-fold: true\n    fig-cap-location: bottom\n    tbl-cap-location: top\n    toc: true\n    toc-depth: 3\n    toc-location: left\n    toc-title: \"Contents\"\ncrossref:\n  fig-title: \"Figure\"\n  eq-title: \"Equation\"\n  tbl-title: \"Table\"\njupyter: python3\nexecute: \n  cache: true\n  freeze: auto\n---\n\n# Objectives\nIn this blog, we are going to dive into ``collaborative filtering`` which is a part of recommendation algorithms used in Netflix.  Netflix may not know these particular properties of the films you watched, but it would be able to see that other people that watched the same movies could watch other movies that you are not watching yet. By applying this technique, Netflix can recommend us the contents of the movies that we have not watched before but relevant to what we liked, which the others too.\n\n[``Collaborative Filtering``](https://www.ibm.com/think/topics/collaborative-filtering) is a ``recommendation system`` that recommends items to users based on how other users with similar preferences and behaviors have interacted with the same item. It is based on the principle that similar users share similar interests and behaviors. \nDifferent to ``content-based filtering``, which recommends items based on the *features of the items themselves*, ``collaborative filtering`` relies on the *collective behavior of users* to make recommendations.\n\n\nThe key idea of ``content-based filtering`` is based on ```latent factors``` which decides what kinds of movies you want to watch.\n# How does it work?\nTo recommend items to users based on their past behavior and preferences, collaborative filtering first needs to find **similar users**. It does this by analyzing user-item interactions and identifying patterns in user behavior. Then, it predicts the **ratings** of items that are not yet rated by the user. To do so, we need to deal with the following questions:\n\n- How to measure user similarity?\n\n- Given that the users behaviors are similar, how to give the rating for an item based on the ratings of others users?\n\n- How to measure the accuracy of the rating since we don't have the ground truth for the unseen items?\n\nTo deal with two former questions, Collaborative filtering uses techniques such as [user-item interactions](https://dl.acm.org/doi/10.1145/371920.372071)^[Herlocker, J. L., et al. (2004). Evaluating collaborative filtering recommender systems. ACM Transactions on Information Systems, 22(1), 5-53.], [similarity measures](https://ieeexplore.ieee.org/document/4781121)^[Bobadilla, J., et al. (2013). Recommender systems survey. Knowledge-based systems, 46, 109-132.], and [matrix factorization](https://ieeexplore.ieee.org/document/5197422)^[Koren, Y., Bell, R., & Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, 42(8), 30-37.]. \n\nTo measure the accuracy of the rating, we can use metrics such as [root mean square error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation) or [mean absolute error (MAE)](https://en.wikipedia.org/wiki/Mean_absolute_error) to evaluate the performance of the recommendation system. `RMSE`  predict ratings for a test dataset of user-item pairs whose rating values are already known. The difference between the known value and the predicted value would be the **error**. Square all the error values for the test set, find the average (or mean), and then take the square root of that average to get the ``RMSE``. On the other hand, `MAE` measures the average magnitude of the errors in a set of predictions, without considering their direction. Itâ€™s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n\n<!-- These metrics compare the predicted ratings with the actual ratings to determine how well the system is performing. -->\n# Collaborative Filtering Techniques\nThere are several techniques in the family of collaborative filtering, which have been widely discussed:\n\n- Memory-based method\n\n- Model-based method\n\n\n## Memory-based method\nMemory-based methods are based on statistical techniques to find similar users or items. \nIt would find the rating $\\mathbf{R}$ for user $\\mathbf{U}$ and item $\\mathbf{I}$ by:\n\n- Finding similar users as user $\\mathbf{U}$ based on their ratings for item $\\mathbf{I}$ that they have rated.\n\n- Calculate rating $\\mathbf{R}$ based as a weighted sum of the ratings given by similar users to item $\\mathbf{I}$.\n\n### Finding similar users with similarity scores\nFor example, there are 4 user $u_1, u_2, u_3, u_4$ $\\in \\mathbf{U}$ have rated two movies $i_1, i_2$ $\\in \\mathbf{I}$ as follows:\n\n::: {#4a4fe26c .cell fig-height='4' execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=458 height=278 fig-align='center'}\n:::\n:::\n\n\nTo define if the preferences of two users are similar, we can use similarity scores between users or items. The most common similarity measures used in memory-based methods are:\n\n- **Cosine similarity**: Measures the cosine of the angle between two vectors in a multi-dimensional space. It is commonly used to measure the similarity between users or items based on their ratings.\n\n- **Pearson correlation**: Measures the linear correlation between two variables. It is often used to find users with similar tastes by comparing their rating patterns.\n\n- **Jaccard similarity**: Measures the similarity between two sets by comparing the size of their intersection to the size of their union. It is useful for finding similar items based on user co-occurrence.\n\nTo calculate similarity using **Cosine similarity**, we need a function that returns a *higher similarity or smaller distance* for a *lower angle* and a *lower similarity or larger distance* for a *higher angle*. The cosine of an angle is a function that decreases from 1 to -1 as the angle increases from 0 to 180.\n\n::: {.callout-note}\n## Centered Cosine Similarity\nIn practice, we center the ratings by subtracting the mean rating of each user from their ratings. This helps to account for individual user biases (e.g., some users may rate all movies higher or lower than others, but they are considered as having the same preferences). The centered cosine similarity is then calculated using these mean-centered ratings.\nThis approach is also used when there are a lot of missing values in the user rating vectors, and we need to place a common value to fill up the missing values.\n:::\n\n### Calculate Rating \n\nThere are multiple way to predict the rating of an item $\\mathbf{I}$ for a user $\\mathbf{U}$, one simple way is to use the average of the ratings for that item given by similar users. The formula for calculating the predicted rating $\\hat{R}_{U,I}$ for user $\\mathbf{U}$ and item $\\mathbf{I}$ is:\n$$\n\\mathbf{R_U} = \\sum_{u =1}^n \\frac{R_{u,I}}{n}\n$$\nThis formula shows that the average rating given by the n similar users is equal to the sum of the ratings given by them divided by the number of similar users, which is n.\n\nTo weight higher score for the users that are more similar to user $u$, we can use the following formula:\n\n$$\n\\mathbf{R_U} = \\frac{\\sum_{u =1}^n R_{u,I}*S_U}{\\sum_{u =1}^n S_U}\n$$\nwhere the similar factor $S_u$, which would act as weights, should be the inverse of the distance discussed above because less distance implies higher similarity. For example, you can subtract the cosine distance from 1 to get cosine similarity.\n\n::: {.callout-note}\n## user-user vs item-item collaborative filtering\nThe techniques, where the rating matrix is used to find similar users based on the ratings they give, is called *user-based* or *user-user collaborative filtering*. If you use the rating matrix to find *similar items* based on the ratings given to them by users, then the approach is called *item-based* or *item-item collaborative filtering*, which is developped by Amazon.\n:::\n\n## Model-based method\nThe model-based collaborative filtering method learns a model from the user-item interactions and uses this model to make predictions. This approach can capture complex patterns in the data and is often more **scalable** than memory-based methods. Some common model-based techniques include:\n\n- **Matrix Factorization**: This technique decomposes the user-item interaction matrix into *lower-dimensional matrices* representing latent factors for users and items. The most popular matrix factorization method is *Singular Value Decomposition (SVD)*.\n\n- **Deep Learning**: Neural networks can be used to learn complex representations of users and items. Techniques like *autoencoders* and *recurrent neural networks (RNNs)* have been applied to collaborative filtering tasks.\n\n### Matrix Factorization\n\nWhen we have a large user-item matrix with many missing values, matrix factorization techniques can help us fill in the gaps. The idea is to factor the original matrix into *two lower-dimensional matrices*: one representing users and the other representing items. This allows us to capture *latent factors* that explain the observed ratings.\n\n![Matrix Factorization Example ([Source: Google Developers](https://developers.google.com/machine-learning/recommendation/collaborative/matrix))](matrix_factor_example.png){#fig-matrix-factorization fig-align=\"center\"}\n\nAs an example @fig-matrix-factorization, a user-item matrix $A \\in \\mathbb{R}^{m \\times n}$ can be factorized into two lower-dimensional matrices (embedding vectors) $U \\in \\mathbb{R}^{m \\times k}$ and $V \\in \\mathbb{R}^{k \\times n}$, where $k$ is the number of *features* or *latent factors*, $m$ is the number of users, and $n$ is the number of items.\n\nUsing embeddings for users and items, we can represent each user or item as a dense vector in a continuous space, capturing their latent characteristics via approximating the original user-item matrix $A$ as follows: $A=U\\times V^T$\n\nTo do that, we need to learn the user and item embeddings from the data. It is achieved by minimizing the difference between the original matrix and the product of the two lower-dimensional matrices.\n$$\n\\min_{U,V} ||A - U \\cdot V^T||_F^2\n$$\nThis corresponds to minimizing the squared [Frobenius distance](https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm) between the original matrix and the reconstructed matrix.\n\nInstead of using techniques like Singular Value Decomposition (SVD) to solve the problem, which is not favorable when matrix $A$ is sparse,  stochastic gradient descent (SGD) is a more feasible candidate.\n\n### Deep-Learning method\nSome disadvantages of matrix factorization for collaborative filtering are:\n\n- Relevancy of recommended item: By using dot product as a similarity measure, popular items are generally recommended for everyone, regardless their different preferences and behavior. \n- Latents features are learned within user-item training set, and can not be captured beyond that.\n\nDeep neural network can deal with these problems by incorporating item features and user features.\n\n![Recommendation with DNN([Source: Google Developers](https://developers.google.com/machine-learning/recommendation/dnn/softmax))](dnn_cf.png){#fig-dnn fig-align=\"center\"}\n\nFigure @fig-dnn shows a deep neural network architecture for collaborative filtering. The input layer consists of user and item features, which are then passed through several hidden layers to learn complex representations. The output layer use *soft-max* to illustrate the probability of a user interacting with an item.\n\n\n# Build a Collaborative Filtering with Python\nIn this section, we will use DNN to build a collaborative filtering model. It includes 3 steps:\n\n- Initialize random parameters of latent features for each user and item. \n\n- Calculate the prediction by taking the *dot product* of user and item embeddings to see how much an user likes/dislike an item.\n\n- Update the user and item embeddings based on the prediction error using backpropagation of *Mean Squared Loss*. \n\n![Initialization of random parameters for user and item embeddings](latent_factor_ini.png){#fig-latent fig-align=\"center\"}\n\n## Data preparation\nIndeed, we can not have access to Netflix's entire dataset of movie watching history, but there is a great dataset that we can yous, called `MovieLen` which contains tens millions of movies ranking.\n\n\n\nTo calculate the result of each user-item interaction, we look for the index of the item in the item latent factor matrix and the index of user in the user latent factor matrix. Then, we perform the *dot product* between the latent vectors.\n\nFurthermore, to capture user positive/negative feedback in their recommendations than others, and some movies are just plain better or worse than others, we can add bias terms for users and items.\n\n::: {#43577ae5 .cell cache='true' message='false' execution_count=3}\n``` {.python .cell-code}\nclass DotProductBias(Module):\n    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n        self.user_factors = Embedding(n_users, n_factors) \n        self.user_bias = Embedding(n_users, 1) \n        self.movie_factors = Embedding(n_movies, n_factors) \n        self.movie_bias = Embedding(n_movies, 1) \n        self.y_range = y_range\n\n    def forward(self, x):\n        users = self.user_factors(x[:,0])\n        movies = self.movie_factors(x[:,1])\n        res = (users * movies).sum(dim=1, keepdim=True)\n        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1]) \n        return sigmoid_range(res, *self.y_range)\n```\n:::\n\n\nThen, we can train the model by first creating data batches using DataLoader.\nWe will use the `CollabDataLoaders` class from FastAI to create our data loaders. \n\n::: {#ec145640 .cell cache='true' message='false' execution_count=4}\n``` {.python .cell-code}\ndls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\nn_users  = len(dls.classes['user']) \nn_movies = len(dls.classes['title'])\n```\n:::\n\n\nLet try to train the model which is based on `DotProductBias` in 5 epochs with learning rate of 0.005.\n\n::: {#7004311d .cell cache='true' message='false' execution_count=5}\n``` {.python .cell-code}\nmodel = DotProductBias(n_users, n_movies, n_factors=50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.873281</td>\n      <td>0.968098</td>\n      <td>00:06</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.601490</td>\n      <td>0.928612</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.430484</td>\n      <td>0.953705</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.307444</td>\n      <td>0.961367</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.304712</td>\n      <td>0.961782</td>\n      <td>00:05</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nAs we can see from the training results, while training loss reduces with each epoch, the validation loss increases, indicating overfitting. It is obvious that the model is not generalizing well to unseen data. \nTo tackle with this issue, we can apply regularization techniques such as ``weight decay``.\n\n::: {.callout-note}\n## Regularization Techniques\n- **Weight Decay**: This technique adds a penalty on the size of the weights to the loss function, discouraging overly complex models.\n- **Dropout**: Randomly dropping units during training to prevent co-adaptation.\n- **Early Stopping**: Monitoring validation loss and stopping training when it starts to increase.\n:::\n\nIn `Weight Decay`, limiting our weights from growing too much is going to hinder the training of the model, but it will yield a state where it generalizes better. The updates of parameters are as follows: `parameters.grad += wd * 2 * parameter`\n\n::: {#02694a23 .cell cache='true' message='false' execution_count=6}\n``` {.python .cell-code}\nmodel = DotProductBias(n_users, n_movies, n_factors=50)\nlearn = Learner(dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 5e-3, wd=0.1)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>epoch</th>\n      <th>train_loss</th>\n      <th>valid_loss</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0.866092</td>\n      <td>0.978580</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.686249</td>\n      <td>0.905717</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.542994</td>\n      <td>0.889370</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.452788</td>\n      <td>0.870501</td>\n      <td>00:05</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.436237</td>\n      <td>0.867133</td>\n      <td>00:05</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\nAs we can see, the training is much better since overfitting has been reduced.\n\n# Conclusion\nIn this blog, \n\n## Key points\n\n\n## Technical Insights\n\n::: {.callout-important}\n## Key Technical Learnings\n- \n- \n:::\n## Future Directions\n\n\n## Final Thoughts\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}